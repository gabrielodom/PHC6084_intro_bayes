---
title: "Lesson 8: Markov Chain Monte Carlo"
author: "Gabriel Odom, Kazi Tanvir Hasan, and Ning Sun"
date: "2022-11-02"
format: html
---

TO NING AND TANVIR: THIS IS A SHORT (1/2) LESSON



# Basic Idea

Markov Chain Monte Carlo (MCMC) methods are very powerful Monte Carlo methods 
that are often used in Bayesian inference. While "classical" Monte Carlo methods
rely on computer-generated samples made up of independent observations, MCMC 
methods are used to generate sequences of dependent observations. 
These sequences are Markov chains, which explains the name of the methods.

Helpful links:

- <https://www.statlect.com/fundamentals-of-statistics/Markov-Chain-Monte-Carlo>
- <https://www.statlect.com/fundamentals-of-statistics/Markov-chains>


## Monte Carlo Simulations

- Uses a computer-generated sample from a given probability distribution to 
estimate a distribution feature.

- Computer-generated sample means using algorithms to produce pseudo-random 
numbers.

- Produce sequences of independent draws from a uniform distribution on the 
interval [0, 1].

- When we canâ€™t analyze a random variableâ€™s probability distribution (e.g., its
expected value), we use the Monte Carlo method to approximate it.

- Computers generate a sample $ğ‘¥_1,ğ‘¥_2,...,ğ‘¥_ğ‘‡$ of independent X draws.

- Calculations use empirical sample distribution.

- The empirical distribution assigns probability $\frac{1}{T}$ to each one of 
the values $_1,ğ‘¥_2,...,ğ‘¥_ğ‘‡$.

### Plug-in Principle

- The plug-in principle is used in probability theory and statistics to 
approximate a probability distribution feature (e.g., expected value, variance, 
quantile).

- In general, the empirical distribution can approximate the true distribution 
of $X$.

- As the sample size $ğ‘‡$ increases, the approximation converges to the true 
value.


## Markov Chains

### Basics of Markov Chains

- MCMC methods work like standard Monte Carlo methods, but the computer-generated
draws $ğ‘‹_1,...,ğ‘‹_ğ‘‡$ are serially correlated.

- Markov Chain realizations are $ğ‘‡$ random variables $ğ‘‹_1,...,ğ‘‹_ğ‘‡$ form a 
Markov Chain.

- Let $ğ‘‹_ğ‘›$ be a sequence of random vectors. The sequence $ğ‘‹_ğ‘›$ is said to 
be a Markov chain if and only if any given term of the sequence $ğ‘‹_ğ‘›$ is 
independent of all terms preceding $ğ‘‹_(ğ‘›âˆ’1)$ conditional on $ğ‘‹_(ğ‘›âˆ’1)$:
\begin{align*}
ğ¹(ğ‘‹_ğ‘› |ğ‘‹_{ğ‘›âˆ’1},ğ‘‹_{ğ‘›âˆ’2},...,ğ‘‹_1 )=ğ¹(ğ‘‹_ğ‘› |ğ‘‹_{ğ‘›âˆ’1} )
\end{align*}
where the letter ğ¹ denotes a conditional distribution function (Taboga, 
Markov chain).

### Markov Property

- A random sequence ${ğ‘‹_ğ‘¡}$ is a Markov chain if and only if, given the current
value ${ğ‘‹_ğ‘¡}$, the future observations $ğ‘‹_(ğ‘¡+ğ‘›)$ are conditionally 
independent of the past values $ğ‘‹_(ğ‘¡âˆ’ğ‘˜)$, for any positive integers $k$ and 
$n$.

$$ P(X_{t+n} = x | X_{t}, X_{t-1}, ... , X_{t-k}) = P(X_{t+n} = x | X_t)  $$

- This Markov property, says that the process is â€œmemorylessâ€.

- The probability of future chain values depends only on $ğ‘‹_ğ‘¡$, regardless of 
how the value was reached

### Conditional & Unconditional Distributions 

Thanks to the Markov property, we basically need only two things to analyze a 
chain:

- the conditional probabilities (or densities) that $X_{t+n}=x_{t+n}$, given that $X_{t}=x_{t}$, denoted by $ğ‘“(ğ‘¥_{t+1} |ğ‘¥_ğ‘¡ )$

- the unconditional probabilities that $X_{t}=x_{t}$, denoted by $ğ‘“(ğ‘¥_ğ‘¡ )$

### Asymptotic Independence

Although this is not true in general of any Markov chain, the chains generated 
by MCMC methods have the following property:

- two variables $X_{t}$ and $X_{t+n}$ are not independent, but they become closer
and closer to being independent as n increases.

This property implies that $f(X_{t+n}|X_t)$ converges to $f(X_{t+n})$ as $n$ 
becomes large.

### Target Distribution

- In an MCMC chain, $ğ‘“(ğ‘¥_ğ‘¡ |ğ‘¥_1 )$ converges to $ğ‘“(ğ‘¥_ğ‘¡ )$, but, as $ğ‘¡$ 
changes, the distributions $ğ‘“(ğ‘¥_ğ‘¡ )$ become almost identical.

- Converge to the stationary distribution of the chain.

- The stationary distribution matches the sample target distribution.

- The larger $ğ‘¡$ , the more $ğ‘“(ğ‘¥_ğ‘¡ |ğ‘¥_1 )$ and $ğ‘“(ğ‘¥_ğ‘¡ )$ resemble the 
target distribution

### A Black-box Approach

- We can imagine an MCMC algorithm as a black box that takes two inputs:

     1. an initial value ğ‘¥_1; \
     2. a target distribution.

- The output is a sequence of values $ğ‘‹_1,...,ğ‘‹_ğ‘‡$.

### Burn-in Sample

- Due to the discrepancy between the target distribution and the first terms of 
the chain, the first MCMC draws are often discarded.

- Burn-in sample is discarded draws.

- By removing the burn-in sample, we keep draws whose distributions are closer 
to the target.

- This reduces bias in MCMC Monte Carlo approximations.

### Correlation and effective sample size

- The accuracy of a standard Monte Carlo simulation depends on the sample size 
$T$: the larger $T$ is, the better the approximation.

- In the case of an MCMC simulation, we need to use the concept of effective 
sample size: $T$ dependent observations are equivalent to a smaller number of 
independent observations.

For example, 1000 dependent observations could be equivalent to 100 independent observations. In this case, we say that the effective sample size is equal to 100.

- Roughly speaking, the higher the correlation between adjacent observations, 
the smaller the effective sample size, and the less accurate the MCMC 
approximation is.


Our lecture on "The Metropolis-Hastings Algorithm" discusses all these point in 
detail.



# Assignment
TO GABRIEL: WRITE AN ASSIGNMENT